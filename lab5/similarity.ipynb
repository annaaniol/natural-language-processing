{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NullHandler', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', '__version__', '_matutils', 'corpora', 'interfaces', 'logger', 'logging', 'matutils', 'models', 'parsing', 'scripts', 'similarities', 'summarization', 'topic_coherence', 'utils']\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "print(dir(gensim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "cwd = os.getcwd()\n",
    "sourcefile = cwd + \"/sources/pap3.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_documents = []\n",
    "\n",
    "with open(sourcefile) as f: \n",
    "    contents = f.read()\n",
    "    for note in contents.split(\"#\"):\n",
    "            if len(note) > 0:\n",
    "                raw_documents.append(note)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 3\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of documents:\",len(raw_documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "gen_docs = [[w.lower() for w in word_tokenize(text)] \n",
    "            for text in raw_documents]\n",
    "# print(gen_docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in dictionary: 27\n"
     ]
    }
   ],
   "source": [
    "dictionary = gensim.corpora.Dictionary(gen_docs)\n",
    "print(\"Number of words in dictionary:\", len(dictionary))\n",
    "# for i in dictionary:\n",
    "#     print(i, dictionary[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 3), (1, 1), (2, 1), (3, 1), (4, 2), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1)], [(0, 2), (4, 2), (6, 1), (8, 1), (9, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 2), (20, 1), (21, 2)], [(0, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1)]]\n"
     ]
    }
   ],
   "source": [
    "corpus = [dictionary.doc2bow(gen_doc) for gen_doc in gen_docs]\n",
    "# print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfModel(num_docs=3, num_nnz=33)\n",
      "nowe: [(0, 3), (1, 1), (2, 1), (3, 1), (4, 2), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1)]\n",
      "nowe: [(0, 2), (4, 2), (6, 1), (8, 1), (9, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 2), (20, 1), (21, 2)]\n",
      "nowe: [(0, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1)]\n",
      "33\n"
     ]
    }
   ],
   "source": [
    "tf_idf = gensim.models.TfidfModel(corpus)\n",
    "# print(tf_idf)\n",
    "# s = 0\n",
    "# for i in corpus:\n",
    "#     print(\"nowe:\",i)\n",
    "#     s += len(i)\n",
    "# print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sim_tfidf(doc):\n",
    "    query_doc = [w.lower() for w in doc]\n",
    "#     print(query_doc)\n",
    "    query_doc_bow = dictionary.doc2bow(query_doc)\n",
    "#     print(query_doc_bow)\n",
    "    query_doc_tf_idf = tf_idf[query_doc_bow]\n",
    "#     print(query_doc_tf_idf)\n",
    "\n",
    "    sim = gensim.similarities.MatrixSimilarity(corpus) \n",
    "    return sim[query_doc_tf_idf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.6939868 , 0.18515123, 0.        ], dtype=float32)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sim_tfidf(gen_docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_top_n_tfidf(n, doc_id):\n",
    "    doc_index = doc_id - 1\n",
    "    top_n = []\n",
    "    sim = get_sim_tfidf(gen_docs[doc_index])\n",
    "    top_per_doc = sim.argsort()[-n:][::-1]\n",
    "    for i in range(0, len(top_per_doc)):\n",
    "        top_per_doc[i] = top_per_doc[i] + 1\n",
    "    return top_per_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_top_n_tfidf(3,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_zeros():\n",
    "    zeros = []\n",
    "    size = len(dictionary)\n",
    "    for i in range (0, size):\n",
    "        row = []\n",
    "        for r in range (0, size):\n",
    "            row.append(0)\n",
    "        zeros.append(row)\n",
    "    return zeros\n",
    "\n",
    "# base_matrix = get_zeros()\n",
    "# for row in base_matrix:\n",
    "#     print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_doc_matrix(doc, k):\n",
    "    doc_matrix = get_zeros()\n",
    "    \n",
    "    query_doc = [w.lower() for w in doc]    \n",
    "    dict_size = len(dictionary)\n",
    "    doc_size = len(query_doc)\n",
    "    \n",
    "    for i in range(0, doc_size):\n",
    "        for slide in range(0, k+1):\n",
    "            if i+slide < doc_size:\n",
    "                first = dictionary.token2id[query_doc[i]]\n",
    "                second = dictionary.token2id[query_doc[i+slide]]\n",
    "                doc_matrix[first][second] += 1\n",
    "    return doc_matrix\n",
    "    \n",
    "# doc_matrix = get_doc_matrix(gen_docs[0], 1)\n",
    "# for row in doc_matrix:\n",
    "#     print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_doc_vector(doc, k):\n",
    "    doc_matrix = get_doc_matrix(doc, k)\n",
    "    doc_vector = []\n",
    "    \n",
    "    counter = 0\n",
    "    \n",
    "    dict_size = len(dictionary)\n",
    "    \n",
    "    for i in range(0, dict_size):\n",
    "        for j in range(0, dict_size):\n",
    "            if doc_matrix[i][j] > 0:\n",
    "                doc_vector.append((counter, doc_matrix[i][j]))\n",
    "            counter += 1\n",
    "    return doc_vector\n",
    "\n",
    "# doc_vector = get_doc_vector(gen_docs[0], 1)\n",
    "# for el in doc_vector:\n",
    "#     print(el)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.26179168, 0.11065666], dtype=float32)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1 = get_doc_vector(gen_docs[0], 2)\n",
    "v2 = get_doc_vector(gen_docs[1], 2)\n",
    "v3 = get_doc_vector(gen_docs[2], 2)\n",
    "\n",
    "corpus = []\n",
    "corpus.append(v1)\n",
    "corpus.append(v2)\n",
    "corpus.append(v3)\n",
    "\n",
    "sim = gensim.similarities.MatrixSimilarity(corpus) \n",
    "sim[v1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_graph_corpus(k):\n",
    "    doc_count = len(gen_docs)\n",
    "    corpus = []\n",
    "    for i in range(0, doc_count):\n",
    "        v = get_doc_vector(gen_docs[i], k)\n",
    "        corpus.append(v)\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sim_graph(doc, k):\n",
    "    corpus = get_graph_corpus(k)\n",
    "    doc_vector = get_doc_vector(doc, k)\n",
    "    sim = gensim.similarities.MatrixSimilarity(corpus) \n",
    "    return sim[doc_vector]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n_graph(n, doc_id, k):\n",
    "    doc_index = doc_id - 1\n",
    "    top_n = []\n",
    "    sim = get_sim_graph(gen_docs[doc_index], k)\n",
    "    top_per_doc = sim.argsort()[-n:][::-1]\n",
    "    for i in range(0, len(top_per_doc)):\n",
    "        top_per_doc[i] = top_per_doc[i] + 1\n",
    "    return top_per_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 3])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_top_n_graph(3,2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(note_id, k):\n",
    "    print(get_top_n_tfidf(10,note_id))\n",
    "    print(get_top_n_graph(10,note_id,k))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 1 3]\n",
      "[2 1 3]\n"
     ]
    }
   ],
   "source": [
    "experiment(2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
